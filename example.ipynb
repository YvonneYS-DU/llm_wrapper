{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b81e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Wrapper Example - Simple Usage Guide\n",
    "\n",
    "from llm_wrapper import Agents\n",
    "import asyncio\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "import os\n",
    "\n",
    "# Note: Set your API keys as environment variables\n",
    "# export OPENAI_API_KEY=\"your-openai-api-key\"\n",
    "# export ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n",
    "\n",
    "print(\"üöÄ LLM Wrapper Example - Let's get started!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996b14f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup LLM Models\n",
    "# Create models with environment variables instead of hardcoded API keys\n",
    "\n",
    "# OpenAI GPT-4o-mini (cost-effective)\n",
    "llm_4o_mini = ChatOpenAI(\n",
    "    model_name='gpt-4o-mini',\n",
    "    temperature=0,\n",
    "    api_key=os.getenv('OPENAI_API_KEY', 'your-openai-api-key')\n",
    ")\n",
    "\n",
    "# Claude 3.5 Sonnet (high performance)\n",
    "llm_claude = ChatAnthropic(\n",
    "    model_name='claude-3-5-sonnet-20241022',\n",
    "    temperature=0,\n",
    "    api_key=os.getenv('ANTHROPIC_API_KEY', 'your-anthropic-api-key')\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Models initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2uj54mt818u",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Basic Text Prompt Example\n",
    "# Simple text-only prompt with parameter substitution\n",
    "\n",
    "# Define a prompt template with parameters\n",
    "text_prompt = \"You are a helpful assistant. Answer this question: {question}\"\n",
    "\n",
    "# Create a chain\n",
    "chain = Agents.chain_create(\n",
    "    model=llm_4o_mini,\n",
    "    text_prompt_template=text_prompt,\n",
    "    image_prompt_template=False,\n",
    "    output_parser=StrOutputParser()\n",
    ")\n",
    "\n",
    "# Use the chain with parameters\n",
    "response = Agents.chain_batch_generator(\n",
    "    chain=chain,\n",
    "    dic={\"question\": \"What is the capital of France?\"}\n",
    ")\n",
    "\n",
    "print(\"üî§ Basic Text Example:\")\n",
    "print(f\"Response: {response}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gk96j5dlxsc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Image Prompt Example\n",
    "# Working with images using base64 encoding\n",
    "\n",
    "import base64\n",
    "\n",
    "# Example: Convert image to base64 (you need an actual image file)\n",
    "def image_to_base64(image_path):\n",
    "    \"\"\"Convert image file to base64 string\"\"\"\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Image file not found: {image_path}\")\n",
    "        return None\n",
    "\n",
    "# Create a chain with image support\n",
    "image_prompt = \"Describe what you see in this image: {base64_image}\"\n",
    "\n",
    "chain_with_image = Agents.chain_create(\n",
    "    model=llm_claude,  # Claude is good with images\n",
    "    text_prompt_template=image_prompt,\n",
    "    image_prompt_template=True,\n",
    "    output_parser=StrOutputParser()\n",
    ")\n",
    "\n",
    "response_with_image = Agents.chain_batch_generator(\n",
    "    chain=chain_with_image,\n",
    "    dic={\"base64_image\": image_to_base64('path/to/your/image.jpg')}  # Replace with your image path\n",
    ")\n",
    "\n",
    "# For demonstration, we'll show the structure without actual image\n",
    "print(\"üì∏ Image Prompt Example:\")\n",
    "print(\"To use with actual image:\")\n",
    "print(\"1. Convert image to base64: image_b64 = image_to_base64('path/to/image.jpg')\")\n",
    "print(\"2. Call chain: response = Agents.chain_batch_generator(chain_with_image, {'base64_image': image_b64})\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0kdlim1gg3x",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Different Output Parsers Example\n",
    "# String vs JSON output\n",
    "\n",
    "# JSON Output Parser Example\n",
    "json_prompt = \"\"\"\n",
    "Analyze the sentiment of this text and return a JSON object with the following structure:\n",
    "{\n",
    "  \"sentiment\": \"positive/negative/neutral\",\n",
    "  \"confidence\": 0.95,\n",
    "  \"key_phrases\": [\"phrase1\", \"phrase2\"]\n",
    "}\n",
    "\n",
    "Text to analyze: {text}\n",
    "\"\"\"\n",
    "\n",
    "# Create chain with JSON output parser\n",
    "json_chain = Agents.chain_create(\n",
    "    model=llm_4o_mini,\n",
    "    text_prompt_template=json_prompt,\n",
    "    image_prompt_template=False,\n",
    "    output_parser=JsonOutputParser()\n",
    ")\n",
    "\n",
    "# Test with JSON output\n",
    "try:\n",
    "    json_response = Agents.chain_batch_generator(\n",
    "        chain=json_chain,\n",
    "        dic={\"text\": \"I love this product! It's amazing and works perfectly.\"}\n",
    "    )\n",
    "    print(\"üìä JSON Output Example:\")\n",
    "    print(f\"Response: {json_response}\")\n",
    "    print(f\"Type: {type(json_response)}\")\n",
    "except Exception as e:\n",
    "    print(f\"JSON parsing might fail if model doesn't return valid JSON: {e}\")\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jqspq555nb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Async/Sync Calling Examples\n",
    "# Different ways to call the chain\n",
    "\n",
    "# Sync (blocking) call\n",
    "sync_prompt = \"Translate this to French: {text}\"\n",
    "sync_chain = Agents.chain_create(\n",
    "    model=llm_4o_mini,\n",
    "    text_prompt_template=sync_prompt,\n",
    "    output_parser=StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"üîÑ Sync Call Example:\")\n",
    "sync_response = Agents.chain_batch_generator(\n",
    "    chain=sync_chain,\n",
    "    dic={\"text\": \"Hello, how are you?\"}\n",
    ")\n",
    "print(f\"Sync Response: {sync_response}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Async (non-blocking) call\n",
    "async def async_example():\n",
    "    print(\"‚ö° Async Call Example:\")\n",
    "    async_response = await Agents.chain_batch_generator_async(\n",
    "        chain=sync_chain,\n",
    "        dic={\"text\": \"Good morning!\"},\n",
    "        delay=0.5  # Optional delay\n",
    "    )\n",
    "    print(f\"Async Response: {async_response}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Run async example\n",
    "await async_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognbphdlei",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Streaming Example\n",
    "# Real-time response streaming\n",
    "\n",
    "print(\"üåä Streaming Example:\")\n",
    "stream_prompt = \"Tell me a short story about {topic}\"\n",
    "stream_chain = Agents.chain_create(\n",
    "    model=llm_4o_mini,\n",
    "    text_prompt_template=stream_prompt,\n",
    "    output_parser=StrOutputParser()\n",
    ")\n",
    "\n",
    "# Stream the response\n",
    "print(\"Story about space exploration:\")\n",
    "for chunk in Agents.chain_stream_generator(\n",
    "    chain=stream_chain,\n",
    "    dic={\"topic\": \"space exploration\"}\n",
    "):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zmb86mezbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Multi-Image Example\n",
    "# Working with multiple images simultaneously\n",
    "\n",
    "# Example with multiple images\n",
    "multi_image_prompt = \"Compare these images and describe the differences\"\n",
    "\n",
    "# Create base64 image list (example structure)\n",
    "# In practice, you would load actual images\n",
    "example_images = [\n",
    "    \"base64_image_1_here\",  # Replace with actual base64 image\n",
    "    \"base64_image_2_here\"   # Replace with actual base64 image\n",
    "]\n",
    "\n",
    "# Create multi-image chain\n",
    "multi_image_chain = Agents.chain_create(\n",
    "    model=llm_claude,\n",
    "    text_prompt_template=multi_image_prompt,\n",
    "    image_list=example_images,\n",
    "    fill_image=False,  # Use placeholders img1, img2, etc.\n",
    "    output_parser=StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"üñºÔ∏è Multi-Image Example:\")\n",
    "print(\"To use with actual images:\")\n",
    "print(\"1. Load images: images = [image_to_base64('img1.jpg'), image_to_base64('img2.jpg')]\")\n",
    "print(\"2. Create chain with image_list=images\")\n",
    "print(\"3. Call with image parameters: {'img1': base64_img1, 'img2': base64_img2}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u30bzca2ty",
   "metadata": {},
   "source": [
    "# üí° Usage Tips & Best Practices\n",
    "\n",
    "## Key Features:\n",
    "- **Simple API**: Create chains with just one function call\n",
    "- **Multi-modal**: Support for text and image inputs\n",
    "- **Flexible Output**: String or JSON parsing\n",
    "- **Async Support**: Both sync and async execution\n",
    "- **Error Handling**: Built-in retry mechanisms\n",
    "- **Streaming**: Real-time response streaming\n",
    "\n",
    "## Best Practices:\n",
    "1. **Use environment variables** for API keys\n",
    "2. **Choose appropriate models** (GPT-4o-mini for cost, Claude for images)\n",
    "3. **Handle errors gracefully** with try-catch blocks\n",
    "4. **Use async calls** for better performance with multiple requests\n",
    "5. **Stream responses** for better user experience\n",
    "\n",
    "## Common Patterns:\n",
    "- Text-only prompts: `image_prompt_template=False`\n",
    "- Image prompts: Convert images to base64 first\n",
    "- JSON output: Use `JsonOutputParser()` with structured prompts\n",
    "- Multiple images: Use `image_list` parameter\n",
    "\n",
    "## Next Steps:\n",
    "- Check the README.md for more detailed documentation\n",
    "- Explore the source code in llm_wrapper.py\n",
    "- Try different models and parameters\n",
    "- Build your own AI applications!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat",
   "language": "python",
   "name": "chat"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
